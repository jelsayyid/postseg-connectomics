# Experiment Log

This document tracks testing experiments, results, and observations as the pipeline is validated.

---

## Experiment 1: Baseline Unit Test Suite

**Date:** 2026-02-13
**Objective:** Establish baseline — verify all existing unit and integration tests pass.

**Setup:**
- Python 3.10.12, pytest 8.3.1
- All tests run against synthetic in-memory data (no external volumes)
- Install: `pip install -e ".[dev]"`

**Results:**
```
72 passed in 5.22s
```

| Module | Tests | Passed | Failed | Notes |
|--------|-------|--------|--------|-------|
| I/O | 9 | 9 | 0 | NumpyReader + HDF5 roundtrip |
| Fragments | 16 | 16 | 0 | Extraction, store, metadata, skeletonization |
| Graph | 9 | 9 | 0 | Graph construction + spatial index |
| Candidates | 16 | 16 | 0 | All scoring functions + generation |
| Validation | 12 | 12 | 0 | All 7 rules + pipeline |
| Assembly | 8 | 8 | 0 | Topology detection + confidence |
| Pipeline (E2E) | 2 | 2 | 0 | Full run + export verification |

**Observations:**
- All 72 tests pass cleanly with no warnings
- Test execution is fast (~5s total) — all synthetic, no disk I/O bottleneck
- End-to-end test covers fragment extraction through export but uses minimal validation (single MaxDistanceRule)
- No coverage measurement yet — needs `pytest-cov` to quantify

**Action Items:**
- [ ] Run coverage analysis to identify untested code paths
- [ ] Expand E2E tests with more realistic validation configurations
- [ ] Begin Phase 2: stress testing with varied synthetic data

---

## Experiment 2: Coverage Analysis

**Date:** _(pending)_
**Objective:** Measure line and branch coverage to identify gaps.

**Setup:** `pytest tests/ --cov=connectomics_pipeline --cov-report=term-missing`

**Results:** _(pending)_

---

## Experiment 3: Stress Testing with Varied Synthetic Data

**Date:** _(pending)_
**Objective:** Test pipeline robustness with edge-case volumes (empty, single-voxel fragments, heavily fragmented, large label counts).

---

## Experiment 4: Parameter Sensitivity

**Date:** _(pending)_
**Objective:** Evaluate how validation thresholds and scoring weights affect pipeline output (accept/reject/ambiguous ratios).

---

## Experiment 5: Larger Volume Scalability

**Date:** _(pending)_
**Objective:** Test pipeline on progressively larger synthetic volumes to identify performance bottlenecks.

---

_Template for new experiments:_

```markdown
## Experiment N: Title

**Date:**
**Objective:**

**Setup:**
- Configuration changes
- Data description

**Results:**
- Quantitative results (tables, numbers)
- Pass/fail summary

**Observations:**
- What worked, what didn't
- Unexpected behaviors

**Action Items:**
- [ ] Follow-up tasks
```
